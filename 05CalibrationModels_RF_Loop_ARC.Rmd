---
title: "05CalibrationModels_RF_Loop_ARC"
output: html_document
date: "2023-07-30"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

QUESTIONS

-   What is contained in the reference training data file

```{r}
library(dplyr)
library(prospectr)
library (globals)
library(stringr)
library(ggplot2)

setwd("/Users/soils/Library/CloudStorage/OneDrive-CIFOR-ICRAF/Documents/0All_Training/Spectroscopy Data Training-17th May 2023/Predictions")

spectraldata=read.csv("/Users/soils/Library/CloudStorage/OneDrive-CIFOR-ICRAF/Documents/0All_Training/Spectroscopy Data Training-17th May 2023/Data/Cleaned_Raw_spectra.csv")
rownames(spectraldata)<-spectraldata$SSN


#Remove metadata columns when using raw file
# names(spectraldata)
# spectraldata<-spectraldata[,-2:-17]

library("stringr")
#Ensure all the wavenumbers are rounded to one decimal place
names(spectraldata)=round(as.numeric(str_sub(names(spectraldata),2)),1)
names(spectraldata)[1] <- "SSN"

#Read reference data
df1=read.csv("/Users/soils/Library/CloudStorage/OneDrive-CIFOR-ICRAF/Documents/0All_Training/Spectroscopy Data Training-17th May 2023/Data/Ref_Training_Soil.csv")#[,c(1,8:29)]

rownames(df1)<-df1$SSN


##################################### Spectra pre-treatment ###################
#remove the CO2 region from all data
co2rem<-which((as.numeric(colnames(spectraldata[-1]))) < 2380 & (as.numeric(colnames(spectraldata[-1]))) > 2350)
spectraldata.f<-spectraldata[,-co2rem]

#Mean-centering function
center_colmeans <- function(x) {
  xcenter = colMeans(x)
  x - rep(xcenter, rep.int(nrow(x), ncol(x)))
}

#SavitzkyGolay pretreatment
spec_der<-as.data.frame(savitzkyGolay(spectraldata.f[,-1], w=17, p=2, m=1))

#Mean-centering
spec_der.mc_trt<-center_colmeans(spec_der)

spec_trt<-bind_cols(SSN=spectraldata$SSN,spec_der.mc_trt)

###############################################################################

#select only the common soil samples in spectral and wet chemie data
df.f<-df1[is.element(df1$SSN, spectraldata$SSN),]

# #Remove unwanted characters in the dataa
# df.f[sapply(df.f, grepl, pattern = "<")] <- "NA"
# dnmrc <- df.f[,-1] %>% mutate_if(is.character, as.numeric) 
# df.f <- bind_cols(SSN = df.f[,1],dnmrc)

spectraldata.fin<-spectraldata[is.element(spectraldata$SSN, df.f$SSN),]
```

### Splitting Calibration and Validation set & Random Forest

QUESTIONS

-   what is df1 referencing

-   So a lot of the work here will be to see whether the property positions for soils and biochar occur similarly along the spectra

-   What is being defined as looped properties?

TO DO

-   briefly read about what is contained in ithir package

-   update script to remove line references and make the referenced lines more explicit

```{r}

#Set splitting proportion for the calibration and validation data
set.seed(123)
pool=df.f[sample(nrow(df.f), round(0.3*nrow(df.f),0)), ]
pool<-pool[order(pool$SSN),]
poolid<-pool$SSN

##################### Random Forest Modelling #################################
library(randomForest)
library(caret)
#library(pls)
#If package ithir is not available for your version of R
#Use the 3 below lines to install package ithir
# install.packages("devtools") 
# library(devtools)
# install_bitbucket("brendo1001/ithir/pkg") 
library(ithir)

#Available properties to predict
#Incase you want to predict only selected properties,
#get property position by running line 66. Remove hash sign between ")" and "["
#symbols on line 67. Edit properties position and run line 67.
#Always ensure position 1 in always included.
names(df1)
slprptr<-names(df1)#[c(1,2,4,16)]

pred<-as.data.frame(spec_trt[,1])
colnames(pred)<-"SSN"

mdl.stats<-NULL#Model stats container

for(p in 4:length(slprptr)){
  
#Select properties to predict one at a time and remove NAs  
df.sel<-df.f %>% select(SSN, slprptr[p]) %>% na.omit

#Plot and print soil properties boxplots
boxplot(df.sel[,slprptr[p]], las=2, xlab = slprptr[p], ylab = "")
dir.create("Plots_Boxplots")
png(paste0(getwd(),"/Plots_Boxplots/",slprptr[p],".png"))
print(boxplot(df.sel[,slprptr[p]], las=2, xlab = slprptr[p], ylab = ""))
dev.off()

# #Split samples inside loop for variables with many NAs
# #Set splitting proportion for the calibration and validation data
# set.seed(123)
# pool=df.f[sample(nrow(df.sel), round(0.2*nrow(df.sel),0)), ]
# pool<-pool[order(pool$SSN),]
# poolid<-pool$SSN


#Get calibration and validation datasets
val_df<-pool
cal_df1 <-subset(df.sel, !(df.sel$SSN %in% val_df$SSN))
# threshold to exclude the extreme 5% values
cal_df <-subset(cal_df1, cal_df1[,2]>quantile(cal_df1[,2], 0.05)&cal_df1[,2] <quantile(cal_df1[,2], 0.95))
val_df1 <-subset(df.sel, (df.sel$SSN %in% val_df$SSN))
val_df <-subset(val_df1, val_df1[,2]>quantile(val_df1[,2], 0.05)&val_df1[,2] <quantile(val_df1[,2], 0.95))
val_df<-val_df[order(rownames(val_df)),]
cal_df<-cal_df[order(rownames(cal_df)),]

#Subset pre-treated spectra by available reference data
val_spec<-spec_trt[is.element(spec_trt$SSN, val_df$SSN),]
cal_spec<-spec_trt[is.element(spec_trt$SSN, cal_df$SSN),]
cal_spec<-cal_spec[order(cal_spec$SSN),]
val_spec<-val_spec[order(val_spec$SSN),]


#Get no of calibration and validation datasets
N_cal<-nrow(cal_spec)
N_val<-nrow(val_spec)

#Model data
Xcal.f=cal_spec[,-1]
Xval.f=val_spec[,-1]
dfcal.f=cal_df[,-1]
dfval.f=val_df[,-1]

rf.md <- randomForest(Xcal.f, dfcal.f, ntree=500, mtry=10, importance=TRUE) #500 10

#Generate relevant model name
md.nm<-paste("rf.md",slprptr[p],sep=".")

#Rename model with the looped soil property
assign(x = md.nm, value = get("rf.md", pos = .GlobalEnv), pos = .GlobalEnv)

## predict to validation dataset
rf.prd <- predict(rf.md, Xval.f)


## Return prediction statistics
val.stats=round(goof(dfval.f,rf.prd, type = "spec"),3)
val.stats<-bind_cols(Property=paste0(Property=slprptr[p],"_val"),N=N_val,val.stats)
val.stats
## calibration statistics
rf_pc <- predict(rf.md, Xcal.f)
rf.cal=round(goof(dfcal.f,rf_pc, type = "spec"),3)
cal.stats<-bind_cols(Property=paste0(Property=slprptr[p],"_cal"),N=N_cal,rf.cal)
cal.stats

################### Get model statistics #########################
mdstats<-bind_rows(cal.stats,val.stats)

#Create model stats labels for the plot
slct.stats<-as.data.frame(t(mdstats[,c("Property","N","R2","RMSE","bias","RPIQ" )]))
names(slct.stats)<-NULL
slct.stats<-bind_cols(rownames(slct.stats),slct.stats[,2])
valbls<-paste0(c("N","R2","RMSE","bias","RPIQ"), "\n")
valsts<-paste0(c(slct.stats[2,2],slct.stats[3,2],slct.stats[4,2],slct.stats[5,2],slct.stats[6,2]))
valstats<-paste(valbls,valsts)

#Bind all looped properties model stats
mdl.stats<-bind_rows(mdl.stats,mdstats)


lgth<-length(sort(dfval.f,decreasing=F))

seq.int(sort(dfval.f,decreasing=F)[1], sort(dfval.f,decreasing=F)[lgth],length.out=4)

#Plot validation plot
plot(dfval.f,rf.prd,pch=10,
     xlab=paste('Measured',names(val_df)[2],sep="_"),
     ylab=paste('Predicted',names(val_df)[2],sep="_"), 
     xlim = range(c(dfval.f,rf.prd)),
     ylim = range(c(dfval.f,rf.prd)),
     mtext(valstats[-1],side=3, at=c(seq.int(sort(dfval.f,decreasing=F)[1], sort(dfval.f,decreasing=F)[lgth],length.out=4)))
     )   ## plot the predicted vs. measured in the validation
abline(a = 0, b = 1)


dir.create("Plots_Validationplots")
png(paste0(getwd(),"/Plots_Validationplots/",slprptr[p],".png"))
print(plot(dfval.f,rf.prd,pch=10,
           xlab=paste('Measured',names(val_df)[2],sep="_"),
           ylab=paste('Predicted',names(val_df)[2],sep="_"), 
           xlim = range(c(dfval.f,rf.prd)),
           ylim = range(c(dfval.f,rf.prd)),
           mtext(valstats[-1],side=3, at=c(seq.int(sort(dfval.f,decreasing=F)[1], sort(dfval.f,decreasing=F)[lgth],length.out=4)))
           ))
abline(a = 0, b = 1)
dev.off()


################### Predict all samples #########################
prd.smpls <- predict(rf.md, spec_trt[,-1])

prd<-as.data.frame(prd.smpls)
df.prd<-bind_cols(SSN=rownames(prd),prd)
colnames(df.prd)<-c("SSN",slprptr[p])

pred<-merge(pred,df.prd,by="SSN", all.x = T)
}

#Remove the least reliably predicted texture data (Clay,Sand or Silt)
#Recalculate the removed texture data to make Clay+Sand+Silt=100% content
# if(which(colnames(pred) %in% "Silt")>1){
#   pred<-pred[,-which(colnames(pred) %in% "Silt")]
# }else{}

#Write model statistics and predicted values to the local drive
write.csv(mdl.stats, paste0(getwd(),"/Model_Statistics.csv"),row.names = F)
write.csv(pred, paste0(getwd(),"/Predicted_Soil_Properties.csv"),row.names = F)
getwd()



############# Predicting New Spectra Using Existing Models #####################

new_spectra<-read.csv("/Users/vkarari/Library/CloudStorage/OneDrive-CGIAR/Documents/0All_Training/SA_ARC_Physical_Training_Aug-Sept22/ARC-MIR/Argd_Raw_spectra.csv")

wavenumbers <- as.numeric(str_sub(names(new_spectra),2))
names(new_spectra) <- wavenumbers
names(new_spectra)[1] <- "SSN"
rownames(new_spectra)<-new_spectra$SSN


#Pretreat new data as the calibration data was pretreated
co2rem.n<-which((as.numeric(colnames(new_spectra[-1]))) < 2380 & (as.numeric(colnames(new_spectra[-1]))) > 2350)
newspectra.fin<-new_spectra [,-co2rem.n]

spec_vnew.p<-as.data.frame(savitzkyGolay(newspectra.fin[,-1], w=17, p=2, m=1))
spec_vnew.pm<-center_colmeans(spec_vnew.p)


############### Predict new dataset using RF model #######################
Clay_pNEW_rf <- predict(rf.md.Clay, spec_vnew.pm)

Carbon_pNEW_rf <- predict(rf.md.Carbon, spec_vnew.pm)

CEC_pNEW_rf <- predict(rf.md.CEC, spec_vnew.pm)

PH_CaCl2_pNEW_rf <- predict(rf.md.PH_CaCl2, spec_vnew.pm)


##################### Test models with texture prediction
PredNEW<-bind_cols(SSN=new_spectra$SSN, Clay=Clay_pNEW_rf, Carbon=Carbon_pNEW_rf, CEC=CEC_pNEW_rf, PH_CaCl2=PH_CaCl2_pNEW_rf)

write.csv(PredNEW,"predicted_rf_all_RF.csv", row.names = F)



```
